{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import random\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU availability\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    print('No GPU detected')\n",
    "\n",
    "num_gpus = len(physical_devices)\n",
    "\n",
    "if num_gpus > 0:\n",
    "    print(f\"Number of available GPUs: {num_gpus}\")\n",
    "    for i in range(num_gpus):\n",
    "        print(f\"GPU {i}: {tf.config.experimental.get_device_details(physical_devices[0])}\")\n",
    "else:\n",
    "    print(\"No GPUs available\")\n",
    "\n",
    "device = tf.device('gpu:0' if len(physical_devices) > 0 else 'cpu:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'D:\\Brain Cancer\\Dataset\\Brain_Cancer_processed_4'\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "train_data = keras.utils.image_dataset_from_directory(data_dir, validation_split = 0.1, subset = 'training', seed = 1, shuffle = True, batch_size = 32, image_size=(256,256))\n",
    "\n",
    "test_data = keras.utils.image_dataset_from_directory(data_dir, validation_split = 0.1, subset = 'validation', seed = 1, shuffle = True, batch_size = 32, image_size=(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = pathlib.Path(data_dir)\n",
    "for label in train_data.class_names :\n",
    "    images = list(filenames.glob(f'{label}/*'))\n",
    "    print(f'{label} : {len(images)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.cardinality().numpy(),  test_data.cardinality().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_data.take(152)\n",
    "val_set = train_data.skip(152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.cardinality().numpy(), val_set.cardinality().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images_batch, labels_batch in train_set:\n",
    "    print(images_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = None, None\n",
    "for images, labels in test_data:\n",
    "    if X_test == None or y_test == None:\n",
    "        X_test = images\n",
    "        y_test = labels\n",
    "    else:\n",
    "        X_test = tf.concat([X_test, images], axis = 0)\n",
    "        y_test = tf.concat([y_test, labels], axis = 0)\n",
    "        \n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG19Model = VGG19(include_top = False, weights = 'imagenet', input_shape = (256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG19Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG19Model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Rescaling, GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "X = Rescaling(1./255)\n",
    "X = VGG19Model.output\n",
    "X = GlobalAveragePooling2D()(X)\n",
    "X = Dense(1024, activation='relu')(X)\n",
    "X = Dropout(0.5)(X)\n",
    "X = Dense(512, activation='relu')(X)\n",
    "X = Dropout(0.25)(X)\n",
    "predictions = Dense(3, activation='softmax')(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=Model(inputs=VGG19Model.input,outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss = keras.losses.SparseCategoricalCrossentropy(), optimizer = keras.optimizers.Adam(learning_rate=1e-4), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2 = model2.fit(train_set, epochs=20, validation_data=val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "#model2.save('d:\\\\Balanced Augmented Covid CXR Dataset\\\\Model\\\\VGG19Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(history_df):\n",
    "    plt.figure(figsize = (13, 4), dpi = 120)\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, len(history_df) + 1), history_df['loss'], marker = '.', label = 'Training Loss')\n",
    "    plt.plot(range(1, len(history_df) + 1), history_df['val_loss'], marker = '^', label = 'Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Cross Entropy')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    ax = plt.subplot(1, 2, 2) \n",
    "    plt.plot(range(1, len(history_df) + 1), history_df['accuracy'], marker = '.', label = 'Training Accuracy')\n",
    "    plt.plot(range(1, len(history_df) + 1), history_df['val_accuracy'], marker = '^', label = 'Validation Accurcay')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "        # Specify the directory to save the PDF\n",
    "    save_dir = 'D:\\\\Brain Cancer\\\\PDF'\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    # Full path to save the PDF file\n",
    "    pdf_path = os.path.join(save_dir, 'VGG19_training_curves.pdf')\n",
    "    \n",
    "    # Save the plot as a PDF with tight layout\n",
    "    plt.tight_layout()  # Ensure that layout is tight\n",
    "    plt.savefig(pdf_path, format='pdf', bbox_inches='tight')  \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_curves(pd.DataFrame(history_2.history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model2.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_proba, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = model2.evaluate(test_data, verbose= 1)\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "print(\"Test Accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['brain_glioma', 'brain_menin', 'brain_tumor']\n",
    "print(classification_report(y_test , y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize = (6,6), dpi = 100)\n",
    "sns.heatmap(metrics.confusion_matrix(y_test, y_pred), annot = True, fmt='d', cmap = 'Greens')\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('True Labels')\n",
    "    # Add a title with the model name VGG19\n",
    "plt.title('Confusion Matrix for VGG19')\n",
    "\n",
    "    # Specify the directory to save the PDF\n",
    "save_dir = 'D:\\\\Brain Cancer\\\\PDF'\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "    # Full path to save the PDF file (with VGG19 in the filename)\n",
    "pdf_path = os.path.join(save_dir, 'VGG19_confusion_matrix.pdf')\n",
    "    \n",
    "    # Save the plot as a PDF with tight layout\n",
    "plt.tight_layout()  # Ensure that layout is tight\n",
    "plt.savefig(pdf_path, format='pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot random images from a given dataset, and compare predictions with ground truth\n",
    "def plot_random_predictions(dataset, model):\n",
    "\n",
    "    shuffled_data = dataset.shuffle(10)\n",
    "    class_names = dataset.class_names\n",
    "\n",
    "    for images, labels in shuffled_data.take(1):\n",
    "        plt.figure(figsize = (10, 10), dpi = 120)\n",
    "        y_pred_proba = model.predict(images)\n",
    "\n",
    "    for i in range(9):\n",
    "        index = random.randint(0, len(images))\n",
    "        ax = plt.subplot(3,3, i + 1)\n",
    "\n",
    "        img = images[index].numpy().astype(\"uint8\")\n",
    "        y_true = class_names[labels[index]]\n",
    "        y_pred = class_names[np.argmax(y_pred_proba[index], axis = 0)]\n",
    "      \n",
    "        c = 'g' if y_pred == y_true else 'r'\n",
    "      \n",
    "        plt.imshow(img)\n",
    "        plt.title(f'Predicted : {y_pred}\\nTrue label : {y_true}', c = c)\n",
    "        plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_predictions(test_data, model2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ghost",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
